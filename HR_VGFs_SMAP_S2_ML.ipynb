{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN1sW73mxNV9JM7pqTxeiau",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chchang1990/HR_VGF_S2_ML/blob/main/HR_VGFs_SMAP_S2_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generating High Resolution (10-m) Vegetation Greenness Fraction using Sentinel-2 and SMAP imagery, and Machine Learning**"
      ],
      "metadata": {
        "id": "StjqW7vXKSrN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Vegetation Greenness Fraction (VGF)** describes the proportion of green vegetation over an area. High resolution VGF data is widely used in many aspects. One of its applications is to **monitor the vegetation growth, and crop yields, which provide valuable insight for agriculture activity** (<a href=\"https://www.mdpi.com/2072-4292/11/19/2324\">Tao et al., 2019</a>).\n",
        "\n",
        "Conventionally, VGF are commonly calculated with the **\"<i>relative vegetation abundance algorithm</i>\" by leveraging vegetation index (VI) derived from remotely sensed data**. Simply put, this algorithm calculates VGF as the ratio between the instaneous and the maximal VIs relative to the bare-soil VI. However, **this algorithm requires accurate maximal and bare-soil VIs to give us a skillful VGF estimation, which is quite challenging since they can vary in different geographic regions, and vegetation types** (<a href=\"https://www.sciencedirect.com/science/article/pii/S0924271619302783\">Gao et al., 2020</a>). The level 4 product of the Soil Moisture Active Passive (SMAP) satellite mission, SPL4SMGP, provides the VGF data. However, its 9-km spatial resolution is coarse and may not be fine enough for practical use.\n",
        "\n",
        "In this Colab script, **I demonstrated a machine learning-based approach to generate high-resolution (10-m) VGF from the Sentinel-2 (S2) imagery by leveraging the Google Earth Engine**. Specifically, I used randomly sampled data from coincident historical S2 Normalized Difference Vegetation Index (NDVI) and SMAP VGF as training data to train a random forest regression model. With this model, any updated high-resolution (10-m) S2 NDVI can be used as input to generate the corresponding high-resolution (10-m) VGF."
      ],
      "metadata": {
        "id": "4ketlKSMKqeF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Required Package preparation"
      ],
      "metadata": {
        "id": "OPW_VFibwKI7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install required packages**"
      ],
      "metadata": {
        "id": "AWy8jLiHY5qY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install geemap rioxarray"
      ],
      "metadata": {
        "id": "o96Ma5vaY51b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import relevant packages**"
      ],
      "metadata": {
        "id": "FNOruAKTPuhi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLZw1Wh9KQxq"
      },
      "outputs": [],
      "source": [
        "import ee\n",
        "import geemap\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import xarray as xr\n",
        "import rioxarray\n",
        "import rasterio\n",
        "\n",
        "import datetime\n",
        "\n",
        "#import seaborn as sbn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import google.colab.drive as drive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Authenticate and initialize Earth Engine API**"
      ],
      "metadata": {
        "id": "e95o9CmHtI3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ee.Authenticate()\n",
        "ee.Initialize()"
      ],
      "metadata": {
        "id": "huczeiQxKRPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mount your Google Drive to the Google Colab**"
      ],
      "metadata": {
        "id": "hHTXngnstNMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive/')\n",
        "root_gdrive = '/content/drive/MyDrive/'"
      ],
      "metadata": {
        "id": "fl8q3BDiKRSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZSNQjuIHwZOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Area-Of-Interest (AOI) visualization"
      ],
      "metadata": {
        "id": "N9lWLHUTwSQs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualize AOI**\n",
        "\n",
        "I selected Iowa State as the pilot study site since it has the highest average percentage in the national production of corn and soybean from 2015 - 2019 per USDA (https://ipad.fas.usda.gov/countrysummary/Default.aspx?id=US&crop=Corn)\n",
        "\n"
      ],
      "metadata": {
        "id": "mFj6wBbLZiQL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's first visualize how different crops are distributed over Iowa"
      ],
      "metadata": {
        "id": "s8nYbSB4tmAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aoi = (\n",
        "    ee.FeatureCollection('TIGER/2018/States')\n",
        "    .filter(ee.Filter.eq('NAME', 'Iowa'))\n",
        ").geometry()\n"
      ],
      "metadata": {
        "id": "Y8KcDv-zi7tF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "usda_crop = (\n",
        "    ee.ImageCollection(\"USDA/NASS/CDL\")\n",
        "    .filterDate('2022-01-01','2022-12-31')\n",
        "    .first()\n",
        "    .select('cropland')\n",
        ") .clip(aoi)"
      ],
      "metadata": {
        "id": "tiM78YV2jat8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Map = geemap.Map(center=(42.1,-93.5), zoom=6)\n",
        "Map.addLayer(usda_crop,{},name='USDA NASS Cropland 2021')\n",
        "Map.addLayerControl()\n",
        "Map"
      ],
      "metadata": {
        "id": "FbhlRT8my3dp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the USDA Cropland map, we can see there are widespread crop fields, mostly corn and soybean, except the south side of Iowa."
      ],
      "metadata": {
        "id": "rxIh4LlfuYgX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3o_2G6VmHclV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Use Google Earth Engine API to retrieve and preprocess SMAP, and S2 images**"
      ],
      "metadata": {
        "id": "mc2zYWM8Yqu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Collection retrieval setting"
      ],
      "metadata": {
        "id": "_41EFIDaxY-2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, I selected a target AOI that is in the north Iowa. Let's have a look where the target AOI is located."
      ],
      "metadata": {
        "id": "tstWqU-pqAYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iowa state border\n",
        "#sample_aoi_w, sample_aoi_s, sample_aoi_e, sample_aoi_n = -96.64, 40.41, -90.12, 43.55\n",
        "\n",
        "sample_aoi_w, sample_aoi_s, sample_aoi_e, sample_aoi_n = -94.73, 42.71, -93.38, 43.54\n",
        "sample_aoi = ee.Geometry.BBox(sample_aoi_w, sample_aoi_s, sample_aoi_e, sample_aoi_n)"
      ],
      "metadata": {
        "id": "SBXqO4g8wmH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Map = geemap.Map(center=(42.1,-93.5), zoom=6)\n",
        "Map.addLayer(usda_crop,{},name='USDA NASS Cropland 2021')\n",
        "Map.addLayer(sample_aoi,{},name='Sample AOI')\n",
        "Map.addLayerControl()\n",
        "Map"
      ],
      "metadata": {
        "id": "JwMz8hxKqAmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are some pre-requisite before proceeding. I set up the time span of S2 and SMAP retrieval, and define a mapping function to clip the image collection to the target AOI"
      ],
      "metadata": {
        "id": "biBWcZXvqAyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_date = '2019-01-01'\n",
        "end_date = '2023-12-31'\n",
        "\n",
        "def imgcol_clip(image):\n",
        "    return image.clip(sample_aoi)\n"
      ],
      "metadata": {
        "id": "OOHAfNI-xZnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After setting up the target AOI and the time span of data retrieval, let's proceed to get the data from Google Earth Engine and pre-process them."
      ],
      "metadata": {
        "id": "B5RkMus6x3mX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## S2 image retrieval and processing\n",
        "\n",
        "\n",
        "\n",
        "Firstly, let's retrieve and pre-process the Sentinel-2 images, which include applying cloud mask and scale the data with the given scale factor. I used **Sentinel-2 MSI: MultiSpectral Instrument, Level-2A** images.\n",
        "    \n",
        "    ee.ImageCollection(\"COPERNICUS/S2_SR\")\n",
        "\n",
        "Then, we can calculate the vegetation indices to be used as input of the machine learning regression model, which is the training feature. There are several vegetation indices can be calculated with the multi-spectral S2 imagery. In this project, I calculated NDVI with Near Infra-Red (NIR) and red bands."
      ],
      "metadata": {
        "id": "pclweD5D1yBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function to mask out cloud pixels and apply the scale factor to the data**"
      ],
      "metadata": {
        "id": "F2umNcgj_Wfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def maskS2clouds(image):\n",
        "    qa = image.select('QA60');\n",
        "\n",
        "    # QA has 12 bits from bit-0 to bit-11\n",
        "    # Bits 10 and 11 are clouds and cirrus, respectively.\n",
        "    cloudBitMask = 1 << 10; # Push \"1\" 10 spaces to the left (010000000000)\n",
        "    cirrusBitMask = 1 << 11; # Push \"1\" 11 spaces to the left (100000000000)\n",
        "\n",
        "    # \"bitwiseAnd\" compare the QA and \"cloudBitMask\" and \"cirrusBitMask\"\n",
        "    # then return True if (1) bit-10 of QA and \"cloudBitMask\" do not match (no cloud)\n",
        "    #                     (2) bit-11 of QA and \"cirrusBitMask\" do not match (no cirrus cloud)\n",
        "    #\n",
        "    # Both flags should be set to zero, indicating clear conditions.\n",
        "    # (a pixel that is neither cloud nor cirrus cloud will be retained)\n",
        "    mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0));\n",
        "    #\n",
        "    # Mask out the cloud/cirrus-cloud pixels and scale the data by 10000 (the scale factor of the data)\n",
        "    return image.updateMask(mask).divide(10000).copyProperties(image, ['system:time_start'])"
      ],
      "metadata": {
        "id": "u00LXY0S1yOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5NLqVndy2Znr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Functions to calculate NDVI**"
      ],
      "metadata": {
        "id": "TxrluCYT2Bbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cal_ndvi(image):\n",
        "    ndvi = image.expression(\n",
        "        \"(NIR - RED)/(NIR + RED)\",\n",
        "        {\n",
        "            \"NIR\": image.select('B8'),\n",
        "            \"RED\": image.select('B4')\n",
        "        }\n",
        "    ).rename('NDVI').copyProperties(image, ['system:time_start']);\n",
        "    #image = image.addBands(ndvi)\n",
        "\n",
        "    return ndvi\n"
      ],
      "metadata": {
        "id": "tUkH44EL2BzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**S2 image retrieval, preprocess, and clipping**"
      ],
      "metadata": {
        "id": "g0sJEdEYyMJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Sentinel-2 data from 2018 to 2022 for training\n",
        "s2_ImgCol = (\n",
        "    ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
        "    .filterDate(start_date, end_date)\n",
        "    ##Pre-filter to get less cloudy granules.\n",
        "    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',20))\n",
        "    .filterBounds(aoi)\n",
        ").map(maskS2clouds).map(imgcol_clip)"
      ],
      "metadata": {
        "id": "KUkwVioh_7En"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculate S2 NDVI**"
      ],
      "metadata": {
        "id": "zE3y0KB0ANai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s2_ndvi_ImgCol = s2_ImgCol.map(cal_ndvi)"
      ],
      "metadata": {
        "id": "0hq7z-JjANie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zzpCKOZj_7PJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SMAP image retrieval and processing"
      ],
      "metadata": {
        "id": "AUmCnBEb15xp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Secondly, let's retrieve the SMAP VGF to be used as desired output of the machine learning regression model, which is the training label. I used **SMAP L4 Global 3-hourly 9-km Surface and Root Zone Soil Moisture**.\n",
        "\n",
        "    ee.ImageCollection(\"NASA/SMAP/SPL4SMGP/007\")"
      ],
      "metadata": {
        "id": "84ioSv8o660X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "smap_band = 'vegetation_greenness_fraction'\n",
        "\n",
        "smap_ImgCol = (\n",
        "    ee.ImageCollection(\"NASA/SMAP/SPL4SMGP/007\")\n",
        "    .select(smap_band)\n",
        "    .filterDate(start_date,end_date)\n",
        "    .filterBounds(aoi)\n",
        ").map(imgcol_clip)"
      ],
      "metadata": {
        "id": "bIypl7RN1slx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MOFxM8ylw8Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Randomly sample data points from coincident S2 NDVI and SMAP VGF to build machine learning regression model**\n",
        "\n",
        "After retrieving and pre-processing the S2 NDVI and SMAP VGF, let's go ahead to sample the data points from coincident S2 NDVI and SMAP VGF, so that we can use them to train the machine learning regression model. It requires two steps\n",
        "\n",
        "1. Generate an image colleciton with spatiotemporally coincident S2 NDVI and SMAP VGF\n",
        "\n",
        "2. Randomly sample the data from each image in the spatiotemporally coincident image collection"
      ],
      "metadata": {
        "id": "EH7pu3Pmw6-3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function to put spatiotemporally coincident S2 NDVI and SMAP VGF as one image collection**"
      ],
      "metadata": {
        "id": "tlmC7kzsrJfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def space_time_join(primary_data, secondary_data, space_tolerance=100, time_tolerance=1):\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    primary_data: data used as reference\n",
        "    secondary_data: data to be matched with primary_data\n",
        "    space_tolerance: tolerance to find spatial match (unit: meter)\n",
        "    time_tolerance: tolerance to find temporal match (unit: day)\n",
        "\n",
        "    \"\"\"\n",
        "    def get_geometry(img):\n",
        "        return img.geometry()\n",
        "\n",
        "    def space_time_merge(img):\n",
        "        BeJoined_ImgCol = ee.ImageCollection.fromImages(img.get(primary_data.__class__.__name__))\n",
        "\n",
        "        img_geom = img.geometry(100)\n",
        "        BeJoined_geom = BeJoined_ImgCol.map(get_geometry).union(100).geometry(100)\n",
        "        overlay = img_geom.intersection(BeJoined_geom, 100)\n",
        "\n",
        "        BeJoined_ImgCol = BeJoined_ImgCol.mosaic()\n",
        "\n",
        "        return img.addBands(BeJoined_ImgCol).clip(overlay)\n",
        "\n",
        "\n",
        "    # Define spatiotemporal filter\n",
        "    space_time_filter = ee.Filter.And(\n",
        "        # Time filter\n",
        "        ee.Filter.maxDifference(\n",
        "            **{\n",
        "                \"difference\": time_tolerance * 1000 * 60 * 60 * 24,  # One day in milliseconds\n",
        "                \"leftField\": \"system:time_start\",\n",
        "                \"rightField\": \"system:time_start\",\n",
        "            }\n",
        "        ),\n",
        "        # Space filter\n",
        "        ee.Filter.intersects(\n",
        "            **{\"leftField\": \".geo\", \"rightField\": \".geo\", \"maxError\": space_tolerance}\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    # apply join on collections and save all results\n",
        "    saveAllJoin =  ee.Join.saveAll(**{\n",
        "            \"matchesKey\": primary_data.__class__.__name__,\n",
        "            \"ordering\": \"system:time_start\",\n",
        "            \"ascending\": True\n",
        "        }\n",
        "    )\n",
        "\n",
        "    joined_ImgCol = ee.ImageCollection(saveAllJoin.apply(primary=primary_data, secondary=secondary_data, condition=space_time_filter))\n",
        "    joined_ImgCol = joined_ImgCol.map(space_time_merge)\n",
        "\n",
        "    return joined_ImgCol"
      ],
      "metadata": {
        "id": "2o4KtyG3rJnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function to sample points of data within the AOI along with the acquisition time**"
      ],
      "metadata": {
        "id": "CxAv8rF8qYA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a time series of mean NDVI and CPC in AOI.\n",
        "def add_date(img):\n",
        "    img_date = ee.Date(img.date())\n",
        "    img_date = ee.Number.parse(img_date.format('YYYYMMdd'))\n",
        "    return img.addBands(ee.Image(img_date).rename('Date').toInt())\n",
        "\n",
        "\n",
        "def aoi_sample(img):\n",
        "    sample_data = img.sample(region=sample_aoi, numPixels=30, geometries=True)\n",
        "    return sample_data"
      ],
      "metadata": {
        "id": "TWgQLzpiqZCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function to export the sampled data to Google Drive (It will take awhile, depending on how large your sampled data is)**"
      ],
      "metadata": {
        "id": "8g68oFwqqZrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def export_samples(sampled_feature_collection, root_gdrive, out_fname):\n",
        "    if not os.path.exists(root_gdrive+out_fname+'.csv'):\n",
        "        task = ee.batch.Export.table.toDrive(**{\n",
        "            'collection': sampled_feature_collection,\n",
        "            'description':out_fname,\n",
        "            'fileFormat': 'csv'\n",
        "        })\n",
        "        task.start()\n",
        "\n",
        "        task = ee.batch.Export.table.toAsset(**{\n",
        "            'collection': sampled_feature_collection,\n",
        "            'description':out_fname,\n",
        "            'assetId': 'users/cchang37ee/'+out_fname\n",
        "        })\n",
        "        task.start()\n",
        "        print('Export the data to Google Drive and Earth Engine Asset. Please read the CSV files after it is done.')\n",
        "    else:\n",
        "        print('Training sample already exported.')"
      ],
      "metadata": {
        "id": "yXrCDWYcqZzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine spatiotemporally coincident S2 NDVIs and SMAP VGFs"
      ],
      "metadata": {
        "id": "0uqWjXqdDtEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "smap_ndvi_ImgCol = space_time_join(smap_ImgCol, s2_ndvi_ImgCol)\n"
      ],
      "metadata": {
        "id": "KDfNQXzl85ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Randomly sample points of data to be used for building machine learning model"
      ],
      "metadata": {
        "id": "KRWja6wdVosL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "smap_ndvi_sample = smap_ndvi_ImgCol.map(add_date).map(aoi_sample).flatten()"
      ],
      "metadata": {
        "id": "KXOyS8kGVpeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Export the sampled data to the Google Drive as CSV (and Google Earth Engine Asset). This will take a while."
      ],
      "metadata": {
        "id": "ToAiMJqRGE92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "export_samples(smap_ndvi_sample, root_gdrive, 'smap_ndvi_samples_Iowa_north_30pts')"
      ],
      "metadata": {
        "id": "IEIR7jccB_z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EH9GKAZvxPwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Examine the time-series of S2 NDVI, and SMAP VGF**\n",
        "\n",
        "Before building a machine learning regression model, it is better to check if there is a correlation between the data, which will give us an idea if a regression model can really be built. Let's look at the time-series and scatter plots of the data."
      ],
      "metadata": {
        "id": "17xop_zRxOiw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function of making double y-axis plot and scatter plot**"
      ],
      "metadata": {
        "id": "Af3RlNmN3Fmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_yyplot(data, ax1_data_name, ax2_data_name, ax1_data_band='NDVI', ax2_data_band='vegetation_greenness_fraction'):\n",
        "\n",
        "    data_date = pd.to_datetime(pd.unique(data[\"Date\"]), format='%Y%m%d')\n",
        "\n",
        "    ax1_data = data[[\"Date\",ax1_data_band]] #soil_moisture_am\n",
        "    ax2_data = data[[\"Date\",ax2_data_band]]\n",
        "\n",
        "    fig, ax1 = plt.subplots()\n",
        "\n",
        "    line1 = ax1.plot(data_date, ax1_data.groupby(['Date']).mean())\n",
        "    ax1.set_ylabel(ax1_data_name, color='C0')\n",
        "    ax1.tick_params(axis='x', rotation=45)\n",
        "    ax1.tick_params(axis='y', color='C0', labelcolor='C0')\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "    line2 = ax2.plot(data_date, ax2_data.groupby(['Date']).mean(),'C1')\n",
        "    ax2.set_ylabel(ax2_data_name, color='C1')\n",
        "    ax2.tick_params(axis='y', color='C1', labelcolor='C1')\n",
        "    ax2.spines['right'].set_color('C1')\n",
        "    ax2.spines['left'].set_color('C0')\n",
        "    plt.show()\n",
        "\n",
        "    plt.scatter(ax1_data[ax1_data_band], ax2_data[ax2_data_band])\n",
        "    plt.xlabel(ax1_data_name, fontsize=20)\n",
        "    plt.ylabel(ax2_data_name, fontsize=20)\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Rw880ngT3LH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First of all, Let's read the sampled data from Google Drive"
      ],
      "metadata": {
        "id": "ectsMbGYVgCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    smap_ndvi_samples_df = pd.read_csv(root_gdrive+'smap_ndvi_samples_Iowa_north_30pts.csv')\n",
        "except:\n",
        "    print('There is no sample in the CSV (Corn).')\n"
      ],
      "metadata": {
        "id": "kxb9eWLeVgKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, let's make the time-series and scatter plots"
      ],
      "metadata": {
        "id": "oh5WF0lhrpYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "make_yyplot(smap_ndvi_samples_df, 'S2 NDVI', 'SMAP VGF', 'NDVI', 'vegetation_greenness_fraction')"
      ],
      "metadata": {
        "id": "HkeZUCuPXG1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we look at the scatter plot, apparently there is a hysteresis pattern in how the data points are distributed. In the time-series plot, we can see that right after the SMAP VGF (orange line) reaches the peak value, it drops down rapidly, much faster than the S2 NDVI (blue line), which could be due to the harvest of the crops in the region.\n",
        "\n"
      ],
      "metadata": {
        "id": "OwFTp5OhzQYY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To verify my inference, I separated the data into two groups based on whether the data acquisition time is within the harvest period or not. The average time frame of harvest and non-harvest period for corn and soybean are shown below, which were obtained from USDA website (https://ipad.fas.usda.gov/countrysummary/Default.aspx?id=US&crop=Soybean).\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1-6gE5fC5Fa3nC7m-GJT0_5wrGjGq2RLR)\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1-E3szEBN1Ox77OLrCWiHHGfJGv3LNssq)"
      ],
      "metadata": {
        "id": "6v3OQ7pRsCbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_date = pd.to_datetime(pd.to_datetime(smap_ndvi_samples_df[\"Date\"], format='%Y%m%d').values)\n",
        "ax1_data = smap_ndvi_samples_df[\"NDVI\"]\n",
        "ax2_data = smap_ndvi_samples_df[\"vegetation_greenness_fraction\"]\n",
        "\n",
        "index_harvest_period = np.logical_and(data_date.month>=9, data_date.month<=11)\n",
        "index_nonharvest_period = np.logical_or(data_date.month<9, data_date.month==12)\n",
        "\n",
        "plt.scatter(ax1_data[index_nonharvest_period], ax2_data[index_nonharvest_period])\n",
        "plt.scatter(ax1_data[index_harvest_period], ax2_data[index_harvest_period])\n",
        "plt.xlabel('S2 NDVI', fontsize=20)\n",
        "plt.ylabel('SMAP VGF', fontsize=20)\n",
        "plt.legend(['Non-harvest', 'Harvest'])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_tbCe5gF_pH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the new scatter plot, we can see that the data in each of the separated groups (acquired during the harvest period or not) now have mitigated hysteresis pattern, which verify my inference. It also means that by building two different models for harvest and non-harvest period can help us better estimate the VGFs. The data grouping process may be further refined if a more precise harvesting schedule is available, but let's proceed with what we have at the momment."
      ],
      "metadata": {
        "id": "o5Y7kTjF8mmz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DQnKiLEK9dAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Build a machine learning model which estimate 10-m resolution VGF maps with S2 NDVI**\n",
        "\n",
        "Now, let's build machine learning regression model to estimate 10-m resolution VGF with S2 NDVI. I selected data acquired from 2019 to 2021 as training data, and the rest of data were used as test data.\n",
        "\n",
        "**If you have ready finished sampling the data by running the previous sectors of code, you can start from here directly**"
      ],
      "metadata": {
        "id": "CXE08n5-S2vK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build up the machine learning model"
      ],
      "metadata": {
        "id": "moR5BFZA8PcS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's first split the data into training and test datasets"
      ],
      "metadata": {
        "id": "7Ao8tqKJOWu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_eeDate(feature):\n",
        "    millis = ee.Date.millis(ee.Date.parse('YYYYMMdd',ee.Number(feature.get('Date')).format('%8d')))\n",
        "    return feature.set({'system:time_start':millis})"
      ],
      "metadata": {
        "id": "1A7foin9_oN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_filter(data, feature_name, label_name, training_span, test_span):\n",
        "\n",
        "    data = data.sort('system:time_start',True)\n",
        "\n",
        "    training_st_time = training_span[0]\n",
        "    training_ed_time = training_span[1]\n",
        "\n",
        "    test_st_time = test_span[0]\n",
        "    test_ed_time = test_span[1]\n",
        "\n",
        "    training_data = data.filterDate(training_st_time,training_ed_time).select(['Date','system:time_start',feature_name, label_name]).sort('system:time_start',True)\n",
        "    test_data = data.filterDate(test_st_time,test_ed_time).select(['Date','system:time_start',feature_name, label_name]).sort('system:time_start',True)\n",
        "\n",
        "    return training_data, test_data"
      ],
      "metadata": {
        "id": "5Ml9nefZR2Yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_data = ee.FeatureCollection('users/cchang37ee/smap_ndvi_samples_Iowa_north_30pts').map(add_eeDate)\n",
        "\n",
        "training_span = ['2019-01-01', '2021-12-31']\n",
        "test_span = ['2022-01-01', '2023-12-31']\n",
        "training_data, test_data = train_test_filter(sampled_data, 'NDVI', 'vegetation_greenness_fraction', training_span, test_span)"
      ],
      "metadata": {
        "id": "LOxJAjvVAHKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gkYEj5BCzphL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, since we will be building separated models for harvest and non-harvest periods, let's separate the data accordingly."
      ],
      "metadata": {
        "id": "6opWNYMh8ePs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_grouping(data):\n",
        "\n",
        "    harvest_data = data.filter(ee.Filter.calendarRange(9,11,'month'))\n",
        "    non_harvest_data = data.filter(ee.Filter.Or(ee.Filter.calendarRange(1,8,'month'),ee.Filter.calendarRange(12,12,'month')))\n",
        "\n",
        "    return harvest_data, non_harvest_data"
      ],
      "metadata": {
        "id": "vejeOX8O87Ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_harvest_data, training_non_harvest_data = data_grouping(training_data)\n",
        "test_harvest_data, test_non_harvest_data = data_grouping(test_data)\n"
      ],
      "metadata": {
        "id": "MbmAeYqDnAIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize training sample\n",
        "Map_training_sample = geemap.Map(center=((sample_aoi_s+sample_aoi_n)/2,(sample_aoi_w+sample_aoi_e)/2), zoom=9)\n",
        "Map_training_sample.addLayer(sample_aoi,{},name='Sample AOI')\n",
        "Map_training_sample.addLayer(training_data, {}, \"training sample\")\n",
        "Map_training_sample"
      ],
      "metadata": {
        "id": "kAqkO9_2p5dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have the data ready to train a machine learning regression model, which I used the random forest regression model of Google Earth Engine API. Two random forest regression models were built, one for harvest period, the other one for non-harvest period."
      ],
      "metadata": {
        "id": "Xx-myzrhqs-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trained_harvest_regressor = (\n",
        "    ee.Classifier.smileRandomForest(numberOfTrees = 30)\n",
        "    .setOutputMode('REGRESSION')\n",
        "    .train(**{\n",
        "        \"features\": training_harvest_data,\n",
        "        \"classProperty\": 'vegetation_greenness_fraction',\n",
        "        \"inputProperties\": ['NDVI']}\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "trained_non_harvest_regressor = (\n",
        "    ee.Classifier.smileRandomForest(numberOfTrees = 30)\n",
        "    .setOutputMode('REGRESSION')\n",
        "    .train(**{\n",
        "        \"features\": training_non_harvest_data,\n",
        "        \"classProperty\": 'vegetation_greenness_fraction',\n",
        "        \"inputProperties\": ['NDVI']}\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "HOjnd2W0S5BC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize the result - High-resolution (10-m) VGF estimated from S2 NDVI with machine learning model"
      ],
      "metadata": {
        "id": "a8hdre0L8WYv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have finished training the random forest regression models. Now, let's generate high-resolution (10-m) VGF with S2 NDVI and the trained models."
      ],
      "metadata": {
        "id": "IFuF1gyPw74Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def estimateVGF_harvest(image):\n",
        "    temp = image.classify(trained_harvest_regressor)\n",
        "    temp = temp.where(temp.gt(1), 1)\n",
        "    vgf = temp.where(temp.lt(0), 0)\n",
        "    return vgf\n",
        "\n",
        "def estimateVGF_non_harvest(image):\n",
        "    temp = image.classify(trained_non_harvest_regressor)\n",
        "    temp = temp.where(temp.gt(1), 1)\n",
        "    vgf = temp.where(temp.lt(0), 0)\n",
        "    return vgf"
      ],
      "metadata": {
        "id": "RZM__Mxv0ABr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In case you have finished the data sampling and start from this section directly, I set up the sample AOI and retrieve the USDA cropland layer again here as I want to visualize them along with the S2-estimated high resolution VGF."
      ],
      "metadata": {
        "id": "B-S3Kz9s1tNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iowa state border\n",
        "#sample_aoi_w, sample_aoi_s, sample_aoi_e, sample_aoi_n = -96.64, 40.41, -90.12, 43.55\n",
        "\n",
        "sample_aoi_w, sample_aoi_s, sample_aoi_e, sample_aoi_n = -94.73, 42.71, -93.38, 43.54\n",
        "sample_aoi = ee.Geometry.BBox(sample_aoi_w, sample_aoi_s, sample_aoi_e, sample_aoi_n)\n",
        "\n",
        "usda_crop = (\n",
        "    ee.ImageCollection(\"USDA/NASS/CDL\")\n",
        "    .filterDate('2022-01-01','2022-12-31')\n",
        "    .first()\n",
        "    .select('cropland')\n",
        ") .clip(sample_aoi)"
      ],
      "metadata": {
        "id": "n_DTDORg2jbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doi = '2022-06-20'\n",
        "doi_end = ee.Date(doi).advance(1,'day').format('YYYY-MM-dd')\n",
        "\n",
        "# Retrieve S2 images, calculate NDVI, and estimate the corresponding VGF\n",
        "doi_s2_ndvi_ImgCol = (\n",
        "    ee.ImageCollection(\"COPERNICUS/S2_SR\")\n",
        "    .filterDate(doi, doi_end)\n",
        "    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',20))\n",
        "    .filterBounds(aoi)\n",
        ").map(maskS2clouds).map(imgcol_clip).map(cal_ndvi)\n",
        "\n",
        "if ee.Date(doi).get('month').getInfo()>=9 and ee.Date(doi).get('month').getInfo()<=11:\n",
        "    doi_s2_HRVGF_ImgCol = doi_s2_ndvi_ImgCol.map(estimateVGF_harvest)\n",
        "else:\n",
        "    doi_s2_HRVGF_ImgCol = doi_s2_ndvi_ImgCol.map(estimateVGF_non_harvest)\n",
        "\n",
        "\n",
        "\n",
        "# Retrieve SMAP VGF for visual comparison\n",
        "smap_band = 'vegetation_greenness_fraction'\n",
        "doi_smap_ImgCol = (\n",
        "    ee.ImageCollection(\"NASA/SMAP/SPL4SMGP/007\")\n",
        "    .select(smap_band)\n",
        "    .filterDate(doi, doi_end)\n",
        "    .filterBounds(aoi)\n",
        ").map(imgcol_clip)\n",
        "\n",
        "\n",
        "\n",
        "# Calculate mean S2-estimated hight resolution VGF, and SMAP VGF acquired on the same date\n",
        "mean_doi_s2_HRVGF = doi_s2_HRVGF_ImgCol.reduce(ee.Reducer.mean())\n",
        "mean_doi_smap_VGF = doi_smap_ImgCol.reduce(ee.Reducer.mean())"
      ],
      "metadata": {
        "id": "Rw7GLZSVOhJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## In case you are interested in plotting each individual VGF map acquired on the same date\n",
        "#ImgCol_size = doi_s2_ndvi_ImgCol.size()\n",
        "#doi_s2_ndvi_ImgList = doi_s2_ndvi_ImgCol.toList(ImgCol_size)\n",
        "#doi_s2_HRVGF_ImgList = doi_s2_HRVGF_ImgCol.toList(ImgCol_size)"
      ],
      "metadata": {
        "id": "uoO7nqiMOhL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's visualize the result. Note that since S2 image has 10m of spatial resolution, which is quite fine. Visualizing on Google Earth Engine map could take a while. If you see nothing on the map at first, probably it's still plotting.\n",
        "\n",
        "On the other hand, since S2 is an optical sensor whose image could be occluded by cloud, if you don't see anything on the map, it's probably because the S2 images on the selected date-of-interest were too cloudy and were completely masked out. In this case, you can try another date-of-interest and give it a shot."
      ],
      "metadata": {
        "id": "f0JcjJHWx51T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vis_VGF = {\n",
        "   'min':0.4,\n",
        "   'max':1,\n",
        "   #'palette':['saddlebrown','sienna','chocolate','peru','burlywood','moccasin','lemonchiffon','honeydew','palegreen','lightgreen','springgreen','lime','limegreen','green','darkgreen']\n",
        "   'palette':['white','lightgreen','green']\n",
        "}\n",
        "\n",
        "\n",
        "sample_aoi_w, sample_aoi_s, sample_aoi_e, sample_aoi_n\n",
        "\n",
        "Map_output = geemap.Map(center=((sample_aoi_s+sample_aoi_n)/2,(sample_aoi_w+sample_aoi_e)/2), zoom=13)\n",
        "Map_output.addLayer(usda_crop,{},name='USDA NASS Cropland 2022')\n",
        "Map_output.addLayer(sample_aoi,{},name='Sample AOI')\n",
        "Map_output.addLayer(mean_doi_smap_VGF,vis_VGF,name='Mean SMAP VGF:'+doi)\n",
        "Map_output.addLayer(mean_doi_s2_HRVGF,vis_VGF,name='Mean S2 VGF:'+doi)\n",
        "\n",
        "## In case you are interested in plotting each individual VGF map acquired on the same date\n",
        "#for ct_img in np.arange(ImgCol_size.getInfo()):\n",
        "#    single_img = ee.Image(doi_s2_ndvi_ImgList.get(int(ct_img)))\n",
        "#    Map_output.addLayer(single_img, vis_ndvi, name='S2 NDVI:'+doi+'-'+str(int(ct_img)).zfill(2))\n",
        "\n",
        "## In case you are interested in plotting each individual VGF map acquired on the same date\n",
        "#for ct_img in np.arange(ImgCol_size.getInfo()):\n",
        "#    single_img = ee.Image(doi_s2_HRVGF_ImgList.get(int(ct_img)))\n",
        "#    Map_output.addLayer(single_img, vis_VGF, name='S2 VGF:'+doi+'-'+str(int(ct_img)).zfill(2))\n",
        "\n",
        "Map_output.addLayerControl()\n",
        "Map_output"
      ],
      "metadata": {
        "id": "EJbJsZ7LOhOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the result above, we can clearly see that we have successfully generated high-resolution (10-m) VGF by using the S2 NDVI and the trained random forest regression model. The 10-m spatial resolution of this S2-estimated VGF is significantly finer than the 9-km resolution of the original SMAP VGF, which is much more informative that can more precisely tell the farmers where their crops are in bad condition and require more cares.\n",
        "\n",
        "Note that the training data here was sampled randomly over the entire AOI that could encompass different land covers (e.g., different crop types). This could be a reason why the scatter plot between SMAP-VGF and S2-NDVI that we saw earlier has disperse data point distribution, even after we split the data into harvest-time, and non-harvest-time groups. Later, training data may be sampled in either stratified way or separately based on the land covers, and see if the regression model can be improved."
      ],
      "metadata": {
        "id": "pr29tSTm3yTq"
      }
    }
  ]
}